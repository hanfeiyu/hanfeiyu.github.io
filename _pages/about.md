---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

# About Me

* Greetings! I'm a fourth-year Ph.D. student in the [Department of Electrical and Computer Engineering](https://www.stevens.edu/school-engineering-science/departments/electrical-computer-engineering), at [Stevens Institute of Technology](https://www.stevens.edu/), advised by Prof. [Hao Wang](https://intellisys.haow.us/haowang/).
* I received my Master's Degree in Computer Science and Systems at [University of Washington Tacoma](https://www.tacoma.uw.edu/), advised by Prof. [Wes J. Lloyd](http://faculty.washington.edu/wlloyd/index.html) and Dr. [Athirai A. Irissappane](https://sites.google.com/view/athirai/). I received my Bachelorâ€™s Degree in Electronic Engineering at [Shanghai Jiao Tong University](http://en.sjtu.edu.cn/).
* My research interests lie in **Cloud Computing**, **Serverless Computing**, **Reinforcement Learning**, **AI/ML systems**, and **LLM serving systems**. Specifically, I focus on improving the resource efficiency of serverless computing systems with AI/ML-driven techniques and building efficient serverless systems for AI/ML training and serving:
  * \[[VLDB'25](https://hanfeiyu.github.io/publications/), [SC'24](https://intellisys.haow.us/assets/pdf/Hanfei_SC24_SwiftRL.pdf), [AAAI'24](https://ojs.aaai.org/index.php/AAAI/article/view/29592)\] Accelerated and cost-effective large-scale **distributed DRL systems** on serverless computing
  * \[[ASPLOS'24](https://doi.org/10.1145/3617232.3624871), [TPDS'24](https://ieeexplore.ieee.org/document/10682062), [HPDC'23](https://dl.acm.org/doi/10.1145/3588195.3592996), [WWW'22](https://doi.org/10.1145/3485447.3511979), [ACSOS'21](https://ieeexplore.ieee.org/document/9659513)\] Efficient resource management and function scheduling for **serverless computing systems**
  * \[[SoCC'24](https://hanfeiyu.github.io/publications/), [In-submission-1](https://hanfeiyu.github.io/publications/)\] Accelerated serverless inference of **Deep Learning systems** and memory-efficient **LLM MoE serving systems**


# News

* **Sep 2024 \[Paper\]** [*Pre-Warming is Not Enough: Accelerating Serverless Inference With Opportunistic Pre-Loading*](https://hanfeiyu.github.io/publications/) accepted by [SoCC 2024](https://acmsocc.org/2024/)   
* **Sep 2023 \[Service\]** Serve as a Reviewer for [ICLR 2025](https://iclr.cc/Conferences/2025)   
* **Aug 2024 \[Paper\]** [*Nitro: Boosting Distributed Reinforcement Learning with Serverless Computing*](https://hanfeiyu.github.io/publications/) accepted by [VLDB 2025](https://vldb.org/2025/)  
* **Aug 2024 \[Paper\]** [*Freyr+: Harvesting Idle Resources in Serverless Computing via Deep Reinforcement Learning*](https://ieeexplore.ieee.org/document/10682062) accepted by [TPDS 2024](https://www.computer.org/csdl/journal/td)  
* **July 2024 \[Service\]** Serve on the Technical Program Committee for [ICPADS 2024](https://attend.ieee.org/icpads/)  
* **June 2024 \[Paper\]** [*Stellaris: Staleness-Aware Distributed Reinforcement Learning with Serverless Computing*](https://intellisys.haow.us/assets/pdf/Hanfei_SC24_SwiftRL.pdf) accepted by [SC 2024](https://sc24.supercomputing.org/) and got into the <span style="color:red">**Best Student Paper Finalist**</span>!  
<!--- * **Feb 2024 \[Service\]** Serve on the Artifact Evaluation Program Committee for [WWW 2024](https://www2024.thewebconf.org/)   --->
<!--- * **Feb 2024 \[Intern\]** I will be working as a research intern at [Microsoft Azure Research](https://www.microsoft.com/en-us/research/group/azure-research-systems/) for the upcoming summer!   --->
<!--- * **Dec 2023 \[Award\]** Received $750 student scholarship from [AAAI 2024](https://aaai.org/aaai-conference/)   --->
<!--- * **Dec 2023 \[Paper\]** [*Cheaper and Faster: Distributed Deep Reinforcement Learning with Serverless Computing*](https://ojs.aaai.org/index.php/AAAI/article/view/29592) accepted by [AAAI 2024](https://aaai.org/aaai-conference/)   --->
<!--- * **Sep 2023 \[Talk\]** Invited to give a talk on "resource harvesting in serverless computing" at [HPCS Lab](https://hpcs.charlotte.edu/), UNC Charlotte   --->
<!--- * **Sep 2023 \[Paper\]** [*RainbowCake: Mitigating Cold-starts in Serverless with Layer-wise Container Caching and Sharing*](https://doi.org/10.1145/3617232.3624871) accepted by [ASPLOS 2024](https://www.asplos-conference.org/asplos2024/)   --->
<!--- * **June 2023 \[Service\]** Serve as a Reviewer for [ECAI 2023](https://ecai2023.eu/)   --->
<!--- * **June 2023 \[Service\]** Serve as a Reviewer for [GLOBECOM 2023](https://globecom2023.ieee-globecom.org/)   --->
<!--- * **April 2023 \[Paper\]** [*Libra: Harvesting Idle Resources Safely and Timely in Serverless Clusters*](https://dl.acm.org/doi/10.1145/3588195.3592996) accepted by [HPDC 2023](https://www.hpdc.org/2023/)   --->
<!--- * **Jan 2022 \[Paper\]** [*Accelerating Serverless Computing by Harvesting Idle Resources*](https://doi.org/10.1145/3485447.3511979) accepted by [WWW 2022](https://www2022.thewebconf.org/)   --->
